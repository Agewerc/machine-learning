{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B. Prediction Uncertainty with Bootstrapping\n",
    "\n",
    "This section is the adaptation of Activity 2 from KNN classification to KNN regression. You use the bootstrapping technique to quantify the uncertainty of predictions for the KNN regressor that you implemented in Section A. Background. Please refer to the background in Section A.\n",
    "\n",
    "\n",
    "### Question 3 [Bootstrapping, 25 Marks]\n",
    "    I. Modify the code in Activity 2 to handle bootstrapping for KNN regression.\n",
    "\n",
    "\n",
    "#### Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries:\n",
    "library(reshape2)\n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Bootstrap function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that generates sample indixes based on bootstrap technique\n",
    "\n",
    "set.seed(1234)\n",
    "boot <- function (original.size=100, sample.size=original.size, times=10){\n",
    "    indx <- matrix(nrow=times, ncol=sample.size)\n",
    "    for (t in 1:times){\n",
    "        indx[t, ] <- sample(x=original.size, size=sample.size, replace = TRUE)\n",
    "    }\n",
    "    return(indx)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN function\n",
    "knn <- function(train.data, train.label, test.data, K=3){\n",
    "\n",
    "    ## count number of train and test samples\n",
    "    train.len <- nrow(train.data)\n",
    "    test.len <- nrow(test.data)\n",
    "    \n",
    "    ## calculate distances between samples\n",
    "    dist <- as.matrix(dist(rbind(test.data, train.data), method= 'manhattan'))[1:test.len, (test.len+1):(test.len+train.len)]\n",
    "    \n",
    "    ## for each test sample...\n",
    "    for (i in 1:test.len){\n",
    "        \n",
    "        ### ...find its K nearest neighbours from training sampels...\n",
    "        nn <- as.data.frame(sort(dist[i,], index.return = TRUE))[1:K,2]\n",
    "        \n",
    "        ###... and calculate the predicted labels according to the majority vote\n",
    "        test.label[i]<- sum(train.label[nn])/K\n",
    "    }\n",
    "    \n",
    "    ## return the class labels as output\n",
    "    return (round(test.label,3))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    II. Load Task1B_tran.csv and Task1B_test.csv sets. Apply your bootstrapping for KNN regression wth times = 50 (the number of subsets), size = 20 (the size of each subse), and change K=1,.., 15 (the neighbourhood size). Now create a boxplot where the x-axis is K, and the y-axis is the averageerror (and the uncertainty around it) corresponding to each K. Save the plot in our Jupyter Notebook file for Question 3. \n",
    "Hint: You can refer to the boxplot in Activity 2 of Module 1. But the error is measured in different ways compared with the KNN classifier.\n",
    "\n",
    "#### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- read.csv(\"data\\\\Sintetic1B_train.csv\")\n",
    "test <- read.csv(\"data\\\\Sintetic1B_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and testing datasets:\n",
    "train.index = 1:nrow(train)\n",
    "train.data <- scale(train[train.index, -5])\n",
    "train.label <- train[train.index, 5]\n",
    "test.data <- scale(test[train.index, -5])\n",
    "test.label <- test[train.index, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Application on KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the parameters\n",
    "K <- 15         # Maximum K for KNN \n",
    "L <- 50         # number of datasets\n",
    "N <- 20         # size of datasets\n",
    "\n",
    "# generate bootstrap indices:\n",
    "boot.indx <- boot(nrow(train.data), N, L)\n",
    "\n",
    "# a dataframe to track the number of missclassified samples in each case\n",
    "error <- data.frame('K'=1:K, 'L'=1:L, 'test'=rep(0,L*K))\n",
    "\n",
    "# THIS MAY TAKE A FEW MINUTES TO COMPLETE\n",
    "## for every k values:\n",
    "for (k in 1: K){\n",
    "    \n",
    "    ### for every dataset sizes:\n",
    "    for (l in 1:L){\n",
    "        \n",
    "        #### calculate iteration index i\n",
    "        i <- (k-1)*L+l\n",
    "        \n",
    "        #### save sample indices that were selected by bootstrap\n",
    "        indx <- boot.indx[l,]\n",
    "        \n",
    "        #### save the value of k and l\n",
    "        error[i,'K'] <- k\n",
    "        error[i,'L'] <- l\n",
    "        \n",
    "        #### calculate and record the train and test missclassification rates\n",
    "        error[i,'test'] <-  sum((knn(train.data[indx, ], train.label[indx], test.data, K=k)  - test.label)^2)/nrow(test.data)\n",
    "    } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error.m <- melt(error, id=c('K', 'L')) # reshape for visualization\n",
    "names(error.m) <- c('K', 'L', 'type', 'error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width=12, repr.plot.height=5) # area of display\n",
    "\n",
    "ggplot(data=error.m[error.m$type=='test',], aes(factor(K), error)) + geom_boxplot(outlier.shape = NA, fill = \"purple\")  + \n",
    "    scale_color_discrete(guide = guide_legend(title = NULL)) + \n",
    "    ggtitle('Mean Squared Error vs. K (Box Plot)') + theme_minimal()\n",
    "# ignore the warnings (because of ignoring outliers)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    III. Based on the plot in the previous part (Part II), how does the test error and its uncertainty behave as K increases? Explain in your Jupyter Notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **As K increases we can see a constant increase in the median of the test error. This is expected because as we have previously discussed, a small K means more model complexity and higher tendency for overfitting and a big K means the opposite, underfitting and less model complexity**. \n",
    "- **On the other hand, as K increases we can see a general trend of more uncertainty in the model, which is consequence of the poor predictive power of model. Since we are working with relatevely small subsets that not necesseraly represent the distribution of the dataset, the model is returning diffenrent predictions with a big range from predicted points.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    IV. Load Task1B_train.csv and Task1B_test.csv sets. Apply your bootstrapping for KNN regression with K= 5(the neighbourhood size), times = 50 (the number of subsets), and change sizes = 5, 10, 15,..., 75 (the size of each subset). Now create a boxplot where the x-axis is ‘sizes’ and the y-axis is the average error (and the uncertainty around it) corresponding to each value of ‘times’. Save the plot in your Jupyter Notebook file for Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the parameters\n",
    "K <- 5                # Maximum K for KNN \n",
    "L <- 50               # number of datasets\n",
    "N <- seq(5,75,5)      # size of datasets\n",
    "\n",
    "\n",
    "# a dataframe to track the number of missclassified samples in each case\n",
    "error <- data.frame(K, 'L'=1:L, 'test'=rep(0,L*length(N)))\n",
    "\n",
    "for (n in N){\n",
    "\n",
    "    # generate bootstrap indices:\n",
    "    boot.indx <- boot(nrow(train.data), n, L)\n",
    "\n",
    "    ### for every dataset sizes:\n",
    "    for (l in 1:L){\n",
    "\n",
    "        #### calculate iteration index i\n",
    "        i <- (n/5-1)*L+l\n",
    "\n",
    "        #### save sample indices that were selected by bootstrap\n",
    "        indx <- boot.indx[l,]\n",
    "\n",
    "        #### save the value of k and l\n",
    "        error[i,'N'] <- n\n",
    "        error[i,'L'] <- l\n",
    "\n",
    "        #### calculate and record the train and test missclassification rates\n",
    "        error[i,'test'] <-  sum((knn(train.data[indx, ], train.label[indx], test.data, K=5)  - test.label)^2)/nrow(test.data) \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot misclassification percentage for train and test data sets\n",
    "error.m <- melt(error, id=c('N', 'L')) # reshape for visualization\n",
    "names(error.m) <- c('N', 'L', 'type', 'miss')\n",
    "\n",
    "ggplot(data=error.m[error.m$type=='test',], aes(factor(N), miss)) + geom_boxplot(outlier.shape = NA, fill = \"purple\")  + \n",
    "    scale_color_discrete(guide = guide_legend(title = NULL)) + \n",
    "    ggtitle('Error vs. Sample Size') + theme_minimal()\n",
    "# ignore the warnings (because of ignoring outliers)\n",
    "options(warn=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    V. Based on the plot in the previous part (Part IV), how does the test error and its uncertainty behave as the size of each subset in bootstrapping increases? Explain in your Jupyter Notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **As the data of the subsets increase there is a constant trend of decrease in the error rate. This is expected and intuitive, because in KNN, as in all machine learning models, the predictive power of the model is extracted from the data. Usually adding more data to a model will increase its accuracy, because the model will have a better fit to the test data. For instance, by extracting a small subset randomly from a big dataset, one can be unlucky and get observations that do not represent the distribuitons of the points from the dataset. However, when we increase the amount of data of the subset, it is very unlikely that the subset will not reflect the original distribution of observations. With respect to KNN it may occur, for instance, because the closest points will not be on the trainning data when calculating the distance and in conseuquence perform a poor prediction**.\n",
    "- **The same is true for the uncertainty of the model, which means, there is a general trend of less variance as the dataset increases in size. If we are working with big subsets sampled for the data, it is likely that the model will retunr similar outcomes and therefore have similar results and less variance. The mathematical explanation behind the fact that adding more data reduces uncertainty may be understood with help of the central limit theorem, but we will not elaborate in this question about as we beleive it is not the purpose**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
